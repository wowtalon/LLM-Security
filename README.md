# LLM-Security

## Content Security

### Prompt Security

- Prompt Injection
- Data Leakage
- TBD

### Output Compliance

- TBD

## Model Security

## LLM Application Security

### [Ollama](https://github.com/ollama/ollama)

- CVE-2024-45436
- CVE-2024-39722
- CVE-2024-39721
- CVE-2024-39720
- CVE-2024-39719
- CVE-2024-37032
- CVE-2024-28224
- [More](https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=ollama)

### [Dify](https://github.com/langgenius/dify)

- [More](https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=dify)

### [LangChain](https://github.com/langchain-ai/langchain)

- [More](https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=langchain)

## Infrastructure Security

### [NVIDIA NIM](https://docs.nvidia.com/nim/large-language-models/latest/introduction.html)

## Tools

- [AI Infra Guard](https://github.com/Tencent/AI-Infra-Guard)
- [Garak](https://github.com/NVIDIA/garak)
- 

## LLM Regulation

- [Safe and Secure Innovation for Frontier Artificial Intelligence Models Act](https://en.wikipedia.org/wiki/Safe_and_Secure_Innovation_for_Frontier_Artificial_Intelligence_Models_Act)
- [Artificial Intelligence Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32024R1689)
- 

## Owasp Top 10 for LLM

https://owasp.org/www-project-top-10-for-large-language-model-applications/
